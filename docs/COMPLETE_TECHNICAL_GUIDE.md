# SmartInvest Bot - Complete Technical Guide

> **Comprehensive end-to-end technical documentation of the SmartInvest automated stock analysis system**

---

## Table of Contents

1. [System Overview](#system-overview)
2. [Architecture](#architecture)
3. [Data Pipeline](#data-pipeline)
4. [Machine Learning System](#machine-learning-system)
5. [Discord Bot](#discord-bot)
6. [Automation System](#automation-system)
7. [Database Schema](#database-schema)
8. [API Integrations](#api-integrations)
9. [Code Structure](#code-structure)
10. [Data Flow](#data-flow)
11. [Deployment](#deployment)
12. [Performance & Scaling](#performance--scaling)

---

## System Overview

### What is SmartInvest?

SmartInvest is a production-grade, automated stock analysis system that:
- Tracks 483+ S&P 500 stocks with 5 years of historical data
- Uses machine learning (XGBoost) to generate buy/sell recommendations
- Analyzes news sentiment using FinBERT (financial BERT model)
- Provides real-time recommendations via Discord bot
- Automatically refreshes data daily at 6 AM ET
- Preserves all historical data for continuous ML training

### Technology Stack

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    TECHNOLOGY STACK                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Backend:
  ‚Ä¢ Python 3.11+
  ‚Ä¢ SQLAlchemy (ORM)
  ‚Ä¢ SQLite (Database)
  ‚Ä¢ Pandas/NumPy (Data processing)

Machine Learning:
  ‚Ä¢ XGBoost (Gradient boosting)
  ‚Ä¢ Scikit-learn (Feature engineering)
  ‚Ä¢ Transformers (FinBERT for sentiment)

APIs:
  ‚Ä¢ yfinance (Historical stock prices)
  ‚Ä¢ Finnhub (Real-time quotes & company info)
  ‚Ä¢ NewsAPI (News articles)
  ‚Ä¢ Discord.py (Bot framework)

Automation:
  ‚Ä¢ Cron (Scheduled tasks)
  ‚Ä¢ Python asyncio (Async operations)

Infrastructure:
  ‚Ä¢ Virtual environment (venv)
  ‚Ä¢ Environment variables (.env)
  ‚Ä¢ Logging (Python logging module)
```

### Key Metrics

- **Stocks tracked**: 483 (96.6% of S&P 500)
- **Historical data**: 5 years per stock (~608,000 price records)
- **News articles**: ~2,000-4,000 (refreshed daily)
- **ML accuracy**: 84% prediction accuracy
- **Database size**: ~65 MB (grows daily)
- **API costs**: $0/month (all free tiers)

---

## Architecture

### High-Level Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     SMARTINVEST ARCHITECTURE                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ   Discord Users  ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ Commands (/daily, /stock)
                             ‚Üì
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ   Discord Bot    ‚îÇ
                    ‚îÇ  (bot_with_real_ ‚îÇ
                    ‚îÇ    data.py)      ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ                    ‚îÇ                    ‚îÇ
        ‚Üì                    ‚Üì                    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  ML Engine    ‚îÇ   ‚îÇ Data Manager  ‚îÇ   ‚îÇ  Collectors   ‚îÇ
‚îÇ               ‚îÇ   ‚îÇ               ‚îÇ   ‚îÇ               ‚îÇ
‚îÇ ‚Ä¢ XGBoost     ‚îÇ‚Üê‚îÄ‚îÄ‚îÇ ‚Ä¢ Storage     ‚îÇ‚Üê‚îÄ‚îÄ‚îÇ ‚Ä¢ yfinance    ‚îÇ
‚îÇ ‚Ä¢ Features    ‚îÇ   ‚îÇ ‚Ä¢ Schema      ‚îÇ   ‚îÇ ‚Ä¢ Finnhub     ‚îÇ
‚îÇ ‚Ä¢ Scoring     ‚îÇ   ‚îÇ ‚Ä¢ Queries     ‚îÇ   ‚îÇ ‚Ä¢ NewsAPI     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
                             ‚Üì
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ  SQLite Database ‚îÇ
                    ‚îÇ                  ‚îÇ
                    ‚îÇ ‚Ä¢ 483 stocks     ‚îÇ
                    ‚îÇ ‚Ä¢ 608K prices    ‚îÇ
                    ‚îÇ ‚Ä¢ 2-4K news      ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚Üë
                             ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ  Cron Automation ‚îÇ
                    ‚îÇ  (6 AM daily)    ‚îÇ
                    ‚îÇ                  ‚îÇ
                    ‚îÇ daily_refresh.py ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Component Breakdown

#### 1. **Data Collection Layer** (`data/collectors.py`)
- Fetches stock prices from yfinance
- Gets company info from Finnhub
- Retrieves news from NewsAPI
- Analyzes sentiment with FinBERT

#### 2. **Data Storage Layer** (`data/storage.py`, `data/schema.py`)
- SQLAlchemy ORM for database operations
- SQLite for persistent storage
- Efficient bulk inserts and queries
- Foreign key relationships

#### 3. **Feature Engineering** (`features/`)
- Technical indicators (RSI, MACD, Bollinger Bands)
- Fundamental metrics (P/E, EPS, market cap)
- Sentiment aggregation (news sentiment scores)

#### 4. **Machine Learning** (`models/`)
- XGBoost classification model
- Feature pipeline for data transformation
- Model training and persistence
- Real-time scoring

#### 5. **Discord Interface** (`bot_with_real_data.py`)
- Async Discord bot using discord.py
- Slash commands for user interaction
- Scheduled tasks for daily updates
- Rich embeds for visualizations

#### 6. **Automation** (`scripts/`)
- Daily data refresh (prices, news, sentiment)
- Model retraining
- Cron job management

---

## Data Pipeline

### Complete Data Flow

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      DATA PIPELINE FLOW                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

STAGE 1: INITIAL LOAD (One-time setup)
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

load_full_sp500.py
    ‚îÇ
    ‚îú‚îÄ Get S&P 500 ticker list (curated, 500 stocks)
    ‚îÇ
    ‚îú‚îÄ For each ticker:
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îú‚îÄ Fetch company info (Finnhub/FMP)
    ‚îÇ   ‚îÇ   ‚Ä¢ Name, sector, industry, market cap
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îú‚îÄ Fetch 5 years price history (yfinance)
    ‚îÇ   ‚îÇ   ‚Ä¢ OHLCV data (Open, High, Low, Close, Volume)
    ‚îÇ   ‚îÇ   ‚Ä¢ Adjusted close for splits/dividends
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îî‚îÄ Save to database
    ‚îÇ       ‚Ä¢ stocks table
    ‚îÇ       ‚Ä¢ stock_prices table
    ‚îÇ
    ‚îî‚îÄ Result: 483 stocks √ó 5 years = ~608,000 price records


STAGE 2: NEWS & SENTIMENT (One-time + daily updates)
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

fetch_news_sentiment.py
    ‚îÇ
    ‚îú‚îÄ For each stock:
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îú‚îÄ Fetch news articles (NewsAPI)
    ‚îÇ   ‚îÇ   ‚Ä¢ Last 7 days
    ‚îÇ   ‚îÇ   ‚Ä¢ Search by ticker + company name
    ‚îÇ   ‚îÇ   ‚Ä¢ Returns: title, source, URL, date
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îú‚îÄ Analyze sentiment (FinBERT - local)
    ‚îÇ   ‚îÇ   ‚Ä¢ Input: article title
    ‚îÇ   ‚îÇ   ‚Ä¢ Output: score (-1 to +1), label (pos/neg/neu)
    ‚îÇ   ‚îÇ   ‚Ä¢ Context: Financial news specific
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îî‚îÄ Save to database
    ‚îÇ       ‚Ä¢ news_articles table
    ‚îÇ       ‚Ä¢ Links to stock via stock_id
    ‚îÇ
    ‚îî‚îÄ Result: ~2,000-4,000 articles with sentiment


STAGE 3: FEATURE ENGINEERING (On-demand + training)
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

features/*.py
    ‚îÇ
    ‚îú‚îÄ Technical Features (features/technical.py)
    ‚îÇ   ‚Ä¢ RSI (Relative Strength Index)
    ‚îÇ   ‚Ä¢ MACD (Moving Average Convergence Divergence)
    ‚îÇ   ‚Ä¢ Bollinger Bands (volatility)
    ‚îÇ   ‚Ä¢ Moving averages (SMA, EMA)
    ‚îÇ   ‚Ä¢ Volume trends
    ‚îÇ   ‚Ä¢ Price momentum
    ‚îÇ
    ‚îú‚îÄ Fundamental Features (features/fundamental.py)
    ‚îÇ   ‚Ä¢ P/E ratio
    ‚îÇ   ‚Ä¢ EPS (Earnings Per Share)
    ‚îÇ   ‚Ä¢ Market capitalization
    ‚îÇ   ‚Ä¢ Debt ratios
    ‚îÇ   ‚Ä¢ ROE (Return on Equity)
    ‚îÇ
    ‚îî‚îÄ Sentiment Features (features/sentiment.py)
        ‚Ä¢ Weighted sentiment (recent = higher weight)
        ‚Ä¢ Sentiment velocity (change over time)
        ‚Ä¢ Positive/negative/neutral counts
        ‚Ä¢ Sentiment consistency (std deviation)
        ‚Ä¢ Attention score (article count)


STAGE 4: ML MODEL TRAINING (Weekly)
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

train_model_v2.py
    ‚îÇ
    ‚îú‚îÄ Load data from database
    ‚îÇ   ‚Ä¢ Price history (all stocks)
    ‚îÇ   ‚Ä¢ News sentiment (all stocks)
    ‚îÇ
    ‚îú‚îÄ Calculate features for each stock
    ‚îÇ   ‚Ä¢ Technical indicators
    ‚îÇ   ‚Ä¢ Sentiment scores
    ‚îÇ
    ‚îú‚îÄ Create labels (target variable)
    ‚îÇ   ‚Ä¢ Future price movement (next 5 days)
    ‚îÇ   ‚Ä¢ Binary: UP (1) or DOWN (0)
    ‚îÇ
    ‚îú‚îÄ Train XGBoost model
    ‚îÇ   ‚Ä¢ 80/20 train/test split
    ‚îÇ   ‚Ä¢ Hyperparameter tuning
    ‚îÇ   ‚Ä¢ Cross-validation
    ‚îÇ
    ‚îú‚îÄ Evaluate performance
    ‚îÇ   ‚Ä¢ Accuracy, precision, recall
    ‚îÇ   ‚Ä¢ Feature importance analysis
    ‚îÇ
    ‚îî‚îÄ Save model
        ‚Ä¢ models/saved_models/model_latest.pkl


STAGE 5: DAILY REFRESH (Automated at 6 AM)
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

daily_refresh.py (triggered by cron)
    ‚îÇ
    ‚îú‚îÄ STEP 1: Update Prices
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îú‚îÄ For each stock:
    ‚îÇ   ‚îÇ   ‚Ä¢ Get latest date in database
    ‚îÇ   ‚îÇ   ‚Ä¢ Fetch new data from (latest+1) to today
    ‚îÇ   ‚îÇ   ‚Ä¢ Insert only new records (preserves historical)
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îî‚îÄ Result: Database always up-to-date
    ‚îÇ
    ‚îú‚îÄ STEP 2: Update Fundamentals (optional, FMP)
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îî‚îÄ Skip if API not available
    ‚îÇ
    ‚îî‚îÄ STEP 3: Update News & Sentiment
        ‚îÇ
        ‚îú‚îÄ For each stock:
        ‚îÇ   ‚Ä¢ Fetch last 7 days news
        ‚îÇ   ‚Ä¢ Analyze sentiment
        ‚îÇ   ‚Ä¢ Save new articles
        ‚îÇ
        ‚îî‚îÄ Result: Fresh sentiment data


STAGE 6: RECOMMENDATION GENERATION (On-demand)
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

bot_with_real_data.py (Discord commands)
    ‚îÇ
    ‚îú‚îÄ User runs /daily command
    ‚îÇ
    ‚îú‚îÄ For each stock in database:
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îú‚îÄ Load from database:
    ‚îÇ   ‚îÇ   ‚Ä¢ Recent price history (60 days)
    ‚îÇ   ‚îÇ   ‚Ä¢ Recent news articles (30 days)
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îú‚îÄ Calculate features:
    ‚îÇ   ‚îÇ   ‚Ä¢ Technical indicators (RSI, MACD, etc.)
    ‚îÇ   ‚îÇ   ‚Ä¢ Sentiment scores
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îú‚îÄ Score with ML model:
    ‚îÇ   ‚îÇ   ‚Ä¢ Load model_latest.pkl
    ‚îÇ   ‚îÇ   ‚Ä¢ Predict: BUY (1) or SELL (0)
    ‚îÇ   ‚îÇ   ‚Ä¢ Get probability (confidence)
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îî‚îÄ Calculate overall score (0-100):
    ‚îÇ       ‚Ä¢ Technical score (40%)
    ‚îÇ       ‚Ä¢ Sentiment score (30%)
    ‚îÇ       ‚Ä¢ ML confidence (30%)
    ‚îÇ
    ‚îú‚îÄ Rank all stocks by score
    ‚îÇ
    ‚îú‚îÄ Select top 10
    ‚îÇ
    ‚îî‚îÄ Display in Discord
        ‚Ä¢ Formatted embed
        ‚Ä¢ Color-coded by score
        ‚Ä¢ Key signals listed
```

### Data Flow Diagram

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ External APIs‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚îú‚îÄ yfinance ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       ‚îú‚îÄ Finnhub ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
       ‚îú‚îÄ NewsAPI ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
       ‚îî‚îÄ FMP ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
                       ‚Üì
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ   Collectors   ‚îÇ
              ‚îÇ  (data fetch)  ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
                       ‚Üì
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ   Database     ‚îÇ
              ‚îÇ  (SQLite ORM)  ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
           ‚îÇ           ‚îÇ           ‚îÇ
           ‚Üì           ‚Üì           ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Features ‚îÇ ‚îÇ   ML     ‚îÇ ‚îÇ Discord  ‚îÇ
    ‚îÇ Engineer ‚îÇ ‚îÇ  Model   ‚îÇ ‚îÇ   Bot    ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ           ‚îÇ           ‚îÇ
           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚Üì
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ Recommendations‚îÇ
              ‚îÇ   to Users     ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Machine Learning System

### Model Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   ML MODEL ARCHITECTURE                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

INPUT FEATURES (20+)
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

Technical Indicators (12 features):
  ‚îú‚îÄ RSI (Relative Strength Index)
  ‚îú‚îÄ MACD (trend momentum)
  ‚îú‚îÄ MACD Signal (crossover detection)
  ‚îú‚îÄ MACD Histogram (divergence)
  ‚îú‚îÄ Bollinger Upper Band
  ‚îú‚îÄ Bollinger Lower Band
  ‚îú‚îÄ Bollinger %B (position in bands)
  ‚îú‚îÄ SMA 20 (short-term trend)
  ‚îú‚îÄ SMA 50 (medium-term trend)
  ‚îú‚îÄ Price momentum (5-day return)
  ‚îú‚îÄ Volume ratio (current vs average)
  ‚îî‚îÄ Volatility (price std deviation)

Sentiment Features (5 features):
  ‚îú‚îÄ Weighted sentiment score
  ‚îú‚îÄ Sentiment velocity (change rate)
  ‚îú‚îÄ Positive article count
  ‚îú‚îÄ Negative article count
  ‚îî‚îÄ Sentiment consistency

Fundamental Features (3 features - optional):
  ‚îú‚îÄ P/E ratio
  ‚îú‚îÄ Market cap category
  ‚îî‚îÄ Sector encoding


XGBOOST MODEL
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

Algorithm: Gradient Boosted Decision Trees
Framework: XGBoost (eXtreme Gradient Boosting)

Hyperparameters:
  ‚Ä¢ max_depth: 6 (tree depth)
  ‚Ä¢ learning_rate: 0.1 (step size)
  ‚Ä¢ n_estimators: 100 (number of trees)
  ‚Ä¢ min_child_weight: 1
  ‚Ä¢ subsample: 0.8 (80% data per tree)
  ‚Ä¢ colsample_bytree: 0.8 (80% features per tree)
  ‚Ä¢ objective: binary:logistic
  ‚Ä¢ eval_metric: logloss

Training:
  ‚Ä¢ Data split: 80% train, 20% test
  ‚Ä¢ Cross-validation: 5-fold
  ‚Ä¢ Early stopping: 10 rounds without improvement
  ‚Ä¢ Class balancing: scale_pos_weight

Performance Metrics:
  ‚Ä¢ Accuracy: 84%
  ‚Ä¢ Precision: 82%
  ‚Ä¢ Recall: 81%
  ‚Ä¢ F1-Score: 81.5%
  ‚Ä¢ AUC-ROC: 0.89


OUTPUT
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

Binary Classification:
  ‚Ä¢ 1 = BUY (price will go up in next 5 days)
  ‚Ä¢ 0 = SELL (price will go down in next 5 days)

Probability Score:
  ‚Ä¢ 0.0 to 1.0 (confidence in prediction)
  ‚Ä¢ Example: 0.87 = 87% confident it's a BUY

Overall Score (0-100):
  ‚Ä¢ Combines: ML probability + technical + sentiment
  ‚Ä¢ Weighted average:
    - ML prediction: 40%
    - Technical indicators: 30%
    - Sentiment score: 30%
```

### Feature Engineering Details

#### Technical Indicators

**RSI (Relative Strength Index)**
```python
def calculate_rsi(prices, period=14):
    """
    Measures overbought/oversold conditions
    Range: 0-100
    > 70 = Overbought (potential sell)
    < 30 = Oversold (potential buy)
    """
    delta = prices.diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
    rs = gain / loss
    rsi = 100 - (100 / (1 + rs))
    return rsi
```

**MACD (Moving Average Convergence Divergence)**
```python
def calculate_macd(prices):
    """
    Trend-following momentum indicator
    MACD = EMA(12) - EMA(26)
    Signal = EMA(9) of MACD
    Histogram = MACD - Signal
    
    Crossover signals:
    - MACD > Signal = Bullish (buy)
    - MACD < Signal = Bearish (sell)
    """
    ema_12 = prices.ewm(span=12).mean()
    ema_26 = prices.ewm(span=26).mean()
    macd = ema_12 - ema_26
    signal = macd.ewm(span=9).mean()
    histogram = macd - signal
    return macd, signal, histogram
```

**Bollinger Bands**
```python
def calculate_bollinger_bands(prices, period=20, std_dev=2):
    """
    Volatility indicator
    Middle = SMA(20)
    Upper = Middle + (2 √ó std)
    Lower = Middle - (2 √ó std)
    
    %B = (Price - Lower) / (Upper - Lower)
    - %B > 1: Above upper band (overbought)
    - %B < 0: Below lower band (oversold)
    - %B ~ 0.5: Near middle (neutral)
    """
    sma = prices.rolling(window=period).mean()
    std = prices.rolling(window=period).std()
    upper = sma + (std_dev * std)
    lower = sma - (std_dev * std)
    percent_b = (prices - lower) / (upper - lower)
    return upper, lower, percent_b
```

#### Sentiment Aggregation

```python
def aggregate_sentiment(articles):
    """
    Aggregates sentiment from multiple news articles
    
    Weighted by recency:
    - Last 24 hours: weight = 1.0
    - 24-48 hours: weight = 0.7
    - 48-72 hours: weight = 0.5
    - >72 hours: weight = 0.3
    
    Returns:
    - weighted_sentiment: -1.0 to +1.0
    - positive_count: number of positive articles
    - negative_count: number of negative articles
    - sentiment_consistency: std deviation (lower = more consistent)
    """
    now = datetime.now()
    weighted_scores = []
    weights = []
    
    for article in articles:
        age_hours = (now - article.published_at).total_seconds() / 3600
        
        if age_hours < 24:
            weight = 1.0
        elif age_hours < 48:
            weight = 0.7
        elif age_hours < 72:
            weight = 0.5
        else:
            weight = 0.3
        
        weighted_scores.append(article.sentiment_score * weight)
        weights.append(weight)
    
    weighted_sentiment = sum(weighted_scores) / sum(weights)
    sentiment_std = np.std([a.sentiment_score for a in articles])
    
    return {
        'weighted_sentiment': weighted_sentiment,
        'positive_count': sum(1 for a in articles if a.sentiment_label == 'positive'),
        'negative_count': sum(1 for a in articles if a.sentiment_label == 'negative'),
        'sentiment_consistency': 100 - min(sentiment_std * 100, 100)
    }
```

### Model Training Process

```python
# Simplified training flow
def train_model():
    # 1. Load data from database
    stocks = db_manager.get_all_stocks()
    
    # 2. Feature matrix (X) and labels (y)
    X = []
    y = []
    
    for stock in stocks:
        # Get price history
        prices = db_manager.get_price_history(stock.id, days=90)
        
        # Calculate technical features
        technical_features = calculate_technical_indicators(prices)
        
        # Get news sentiment
        articles = db_manager.get_news_articles(stock.id, days=30)
        sentiment_features = aggregate_sentiment(articles)
        
        # Combine features
        features = {**technical_features, **sentiment_features}
        X.append(list(features.values()))
        
        # Label: Did price go up in next 5 days?
        future_price = prices[-1].close
        current_price = prices[-6].close
        label = 1 if future_price > current_price else 0
        y.append(label)
    
    # 3. Split data
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )
    
    # 4. Train XGBoost
    model = xgb.XGBClassifier(
        max_depth=6,
        learning_rate=0.1,
        n_estimators=100,
        objective='binary:logistic'
    )
    model.fit(X_train, y_train)
    
    # 5. Evaluate
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    print(f"Accuracy: {accuracy:.2%}")
    
    # 6. Save model
    joblib.dump(model, 'models/saved_models/model_latest.pkl')
```

---

## Discord Bot

### Bot Architecture

```python
class SmartInvestBot:
    """
    Discord bot for stock recommendations
    Uses discord.py library with slash commands
    """
    
    def __init__(self):
        # Discord client with intents
        intents = discord.Intents.default()
        intents.message_content = True
        self.bot = commands.Bot(command_prefix='/', intents=intents)
        
        # Database connection
        self.db_manager = DatabaseManager(Config.DATABASE_URL)
        
        # ML model
        self.model = joblib.load('models/saved_models/model_latest.pkl')
        
        # Setup commands
        self.setup_commands()
    
    def setup_commands(self):
        """Register slash commands"""
        
        @self.bot.tree.command(name="daily")
        async def daily_command(interaction: discord.Interaction):
            """Get top 10 daily stock recommendations"""
            await interaction.response.defer()  # Processing...
            
            # Generate recommendations
            recommendations = self.generate_recommendations(top_n=10)
            
            # Create Discord embed
            embed = self.create_recommendations_embed(recommendations)
            
            # Send to user
            await interaction.followup.send(embed=embed)
        
        @self.bot.tree.command(name="stock")
        @app_commands.describe(ticker="Stock ticker (e.g., AAPL)")
        async def stock_command(interaction: discord.Interaction, ticker: str):
            """Analyze a specific stock"""
            await interaction.response.defer()
            
            # Score single stock
            result = self.score_stock_simple(ticker.upper())
            
            if result:
                embed = self.create_stock_detail_embed(result)
                await interaction.followup.send(embed=embed)
            else:
                await interaction.followup.send(f"‚ùå Stock {ticker} not found")
    
    def generate_recommendations(self, top_n=10):
        """
        Generate stock recommendations
        
        Process:
        1. Load all stocks from database
        2. Calculate features for each
        3. Score with ML model
        4. Rank by overall score
        5. Return top N
        """
        stocks = self.db_manager.get_all_stocks()
        scored_stocks = []
        
        for stock in stocks:
            try:
                score_result = self.score_stock_simple(stock.ticker)
                if score_result:
                    scored_stocks.append(score_result)
            except Exception as e:
                logger.error(f"Error scoring {stock.ticker}: {e}")
                continue
        
        # Sort by overall_score descending
        scored_stocks.sort(key=lambda x: x['overall_score'], reverse=True)
        
        return scored_stocks[:top_n]
    
    def score_stock_simple(self, ticker):
        """
        Score a single stock
        
        Returns dict with:
        - ticker
        - company_name
        - overall_score (0-100)
        - technical_score (0-100)
        - sentiment_score (0-100)
        - ml_probability (0-1)
        - current_price
        - signals (list of key signals)
        """
        stock = self.db_manager.get_stock_by_ticker(ticker)
        if not stock:
            return None
        
        # Get data
        prices = self.db_manager.get_price_history(stock.id, days=60)
        articles = self.db_manager.get_news_articles(stock.id, limit=50)
        
        if len(prices) < 30:
            return None
        
        # Calculate features
        technical_features = self.calculate_technical_features(prices)
        sentiment_features = self.calculate_sentiment_features(articles)
        
        # Combine features
        features = [
            technical_features['rsi'],
            technical_features['macd'],
            technical_features['macd_signal'],
            technical_features['bollinger_position'],
            technical_features['momentum'],
            technical_features['volume_ratio'],
            sentiment_features['weighted_sentiment'],
            sentiment_features['positive_count'],
            sentiment_features['negative_count'],
        ]
        
        # ML prediction
        ml_prob = self.model.predict_proba([features])[0][1]  # Probability of BUY
        
        # Calculate scores
        technical_score = self.calculate_technical_score(technical_features)
        sentiment_score = (sentiment_features['weighted_sentiment'] + 1) * 50  # -1 to +1 ‚Üí 0 to 100
        
        # Overall score (weighted average)
        overall_score = (
            technical_score * 0.3 +
            sentiment_score * 0.3 +
            ml_prob * 100 * 0.4
        )
        
        # Generate signals
        signals = self.generate_signals(technical_features, sentiment_features, ml_prob)
        
        return {
            'ticker': ticker,
            'company_name': stock.company_name,
            'overall_score': int(overall_score),
            'technical_score': int(technical_score),
            'sentiment_score': int(sentiment_score),
            'ml_probability': ml_prob,
            'current_price': prices[-1].close,
            'signals': signals
        }
```

### Discord Embed Formatting

```python
def create_recommendations_embed(self, recommendations):
    """
    Create rich Discord embed for recommendations
    
    Color-coded by score:
    - 80-100: Green (Strong Buy)
    - 60-79: Yellow (Buy)
    - 40-59: Gray (Neutral)
    - 0-39: Red (Sell)
    """
    embed = discord.Embed(
        title="üìà Top 10 Daily Stock Recommendations",
        description=f"Generated at {datetime.now().strftime('%Y-%m-%d %H:%M')}",
        color=discord.Color.green()
    )
    
    for i, stock in enumerate(recommendations[:10], 1):
        # Determine emoji and color
        score = stock['overall_score']
        if score >= 80:
            emoji = "üü¢"
            rating = "STRONG BUY"
        elif score >= 60:
            emoji = "üü°"
            rating = "BUY"
        elif score >= 40:
            emoji = "‚ö™"
            rating = "NEUTRAL"
        else:
            emoji = "üî¥"
            rating = "SELL"
        
        # Format field
        field_name = f"{i}. {emoji} {stock['ticker']} - {stock['company_name'][:30]}"
        field_value = (
            f"**Score:** {score}/100 ({rating})\n"
            f"**Price:** ${stock['current_price']:.2f}\n"
            f"**Signals:** {', '.join(stock['signals'][:3])}"
        )
        
        embed.add_field(
            name=field_name,
            value=field_value,
            inline=False
        )
    
    embed.set_footer(text="SmartInvest Bot ‚Ä¢ ML-Powered Analysis")
    return embed
```

---

## Automation System

### Cron Job Configuration

```bash
# Cron job runs daily at 6:00 AM ET
# Located in: /etc/crontab or user crontab (crontab -e)

# Format: minute hour day month weekday command
0 6 * * * cd /path/to/smartinvest-bot && /path/to/venv/bin/python scripts/daily_refresh.py >> logs/daily_refresh.log 2>&1

# Breakdown:
# 0     = Minute (0 = top of the hour)
# 6     = Hour (6 AM)
# *     = Every day of month
# *     = Every month
# *     = Every day of week
# >>    = Append output to log file
# 2>&1  = Redirect errors to log file
```

### Daily Refresh Script

```python
# scripts/daily_refresh.py

def refresh_stock_prices(db_manager, collector):
    """
    Update stock prices incrementally
    
    Process:
    1. Get all stocks from database
    2. For each stock:
       a. Check latest price date in DB
       b. Fetch new data from (latest+1) to today
       c. Insert only new records
    3. Preserves all historical data
    """
    stocks = db_manager.get_all_stocks()
    
    for stock in stocks:
        # Get latest date
        latest_price = db_manager.get_latest_price(stock.id)
        start_date = latest_price.date + timedelta(days=1)
        
        # Fetch new data
        price_df = collector.fetch_price_history(stock.ticker, period='max')
        
        # Filter to only new data
        price_df = price_df[price_df['date'] >= start_date]
        
        if not price_df.empty:
            # Insert new records
            db_manager.bulk_insert_prices(stock.id, price_df)
            print(f"‚úÖ {stock.ticker}: Added {len(price_df)} new records")

def refresh_news_sentiment(db_manager, news_collector, sentiment_analyzer):
    """
    Update news and sentiment
    
    Process:
    1. Get all stocks
    2. For each stock:
       a. Fetch last 7 days of news
       b. Analyze sentiment
       c. Save new articles (duplicates handled by DB)
    """
    stocks = db_manager.get_all_stocks()
    
    for stock in stocks:
        # Fetch news
        articles = news_collector.fetch_news(stock.ticker, days_back=7)
        
        for article in articles:
            # Analyze sentiment
            sentiment = sentiment_analyzer.analyze_text(article['title'])
            
            # Save to database (handles duplicates)
            db_manager.add_news_article(
                stock_id=stock.id,
                title=article['title'],
                source=article['source'],
                url=article['url'],
                published_at=article['published_at'],
                sentiment_score=sentiment['sentiment_score'],
                sentiment_label=sentiment['sentiment_label']
            )

def main():
    """Main daily refresh execution"""
    # Initialize
    db_manager = DatabaseManager(Config.DATABASE_URL)
    collector = StockDataCollector(
        fmp_api_key=Config.FMP_API_KEY,
        finnhub_api_key=Config.FINNHUB_API_KEY
    )
    news_collector = NewsCollector(Config.NEWS_API_KEY)
    sentiment_analyzer = SentimentAnalyzer()
    
    # Step 1: Update prices
    print("Step 1: Updating stock prices...")
    refresh_stock_prices(db_manager, collector)
    
    # Step 2: Update news & sentiment
    print("Step 2: Updating news & sentiment...")
    refresh_news_sentiment(db_manager, news_collector, sentiment_analyzer)
    
    print("‚úÖ Daily refresh complete!")
```

### Scheduling Timeline

```
TIME     | ACTION                           | DURATION
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
6:00 AM  | Cron triggers daily_refresh.py   | Start
6:00 AM  | Update 483 stock prices          | ~5 min
6:05 AM  | Update news (483 stocks)         | ~8 min
6:13 AM  | Analyze sentiment (2-4K articles)| ~2 min
6:15 AM  | Save all to database             | <1 min
6:16 AM  | Complete, log results            | Done
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
9:30 AM  | Market opens                     | Fresh data ready!
```

---

## Database Schema

### Entity Relationship Diagram

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ     stocks       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ id (PK)          ‚îÇ
‚îÇ ticker (UNIQUE)  ‚îÇ
‚îÇ company_name     ‚îÇ
‚îÇ sector           ‚îÇ
‚îÇ industry         ‚îÇ
‚îÇ market_cap       ‚îÇ
‚îÇ created_at       ‚îÇ
‚îÇ last_updated     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚îÇ 1:N
         ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ         ‚îÇ                      ‚îÇ                  ‚îÇ
    ‚Üì         ‚Üì                      ‚Üì                  ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  stock_prices      ‚îÇ  ‚îÇ  news_articles   ‚îÇ  ‚îÇ recommendations  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ id (PK)            ‚îÇ  ‚îÇ id (PK)          ‚îÇ  ‚îÇ id (PK)          ‚îÇ
‚îÇ stock_id (FK)      ‚îÇ  ‚îÇ stock_id (FK)    ‚îÇ  ‚îÇ stock_id (FK)    ‚îÇ
‚îÇ date               ‚îÇ  ‚îÇ title            ‚îÇ  ‚îÇ overall_score    ‚îÇ
‚îÇ open               ‚îÇ  ‚îÇ url              ‚îÇ  ‚îÇ technical_score  ‚îÇ
‚îÇ high               ‚îÇ  ‚îÇ source           ‚îÇ  ‚îÇ fundamental_score‚îÇ
‚îÇ low                ‚îÇ  ‚îÇ published_at     ‚îÇ  ‚îÇ sentiment_score  ‚îÇ
‚îÇ close              ‚îÇ  ‚îÇ sentiment_score  ‚îÇ  ‚îÇ signals (JSON)   ‚îÇ
‚îÇ volume             ‚îÇ  ‚îÇ sentiment_label  ‚îÇ  ‚îÇ rank             ‚îÇ
‚îÇ adjusted_close     ‚îÇ  ‚îÇ created_at       ‚îÇ  ‚îÇ price_at_rec     ‚îÇ
‚îÇ created_at         ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ created_at       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

UNIQUE INDEX: (stock_id, date)           UNIQUE INDEX: (stock_id, url)
```

### Schema Definitions (SQLAlchemy)

```python
# data/schema.py

class Stock(Base):
    """Stock master table"""
    __tablename__ = 'stocks'
    
    id = Column(Integer, primary_key=True)
    ticker = Column(String(10), unique=True, nullable=False, index=True)
    company_name = Column(String(255), nullable=False)
    sector = Column(String(100))
    industry = Column(String(100))
    market_cap = Column(BigInteger)
    created_at = Column(DateTime, default=datetime.utcnow)
    last_updated = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)
    
    # Relationships
    prices = relationship('StockPrice', back_populates='stock', cascade='all, delete-orphan')
    news = relationship('NewsArticle', back_populates='stock', cascade='all, delete-orphan')
    recommendations = relationship('Recommendation', back_populates='stock', cascade='all, delete-orphan')


class StockPrice(Base):
    """Historical price data"""
    __tablename__ = 'stock_prices'
    
    id = Column(Integer, primary_key=True)
    stock_id = Column(Integer, ForeignKey('stocks.id'), nullable=False)
    date = Column(Date, nullable=False)
    open = Column(Float, nullable=False)
    high = Column(Float, nullable=False)
    low = Column(Float, nullable=False)
    close = Column(Float, nullable=False)
    volume = Column(BigInteger, nullable=False)
    adjusted_close = Column(Float)
    created_at = Column(DateTime, default=datetime.utcnow)
    
    # Relationships
    stock = relationship('Stock', back_populates='prices')
    
    # Unique constraint on stock_id + date
    __table_args__ = (
        Index('idx_stock_date', 'stock_id', 'date', unique=True),
        Index('idx_date', 'date'),  # For date range queries
    )


class NewsArticle(Base):
    """News articles with sentiment"""
    __tablename__ = 'news_articles'
    
    id = Column(Integer, primary_key=True)
    stock_id = Column(Integer, ForeignKey('stocks.id'), nullable=False)
    title = Column(String(500), nullable=False)
    url = Column(String(1000), nullable=False)
    source = Column(String(100))
    published_at = Column(DateTime, nullable=False)
    sentiment_score = Column(Float, nullable=False)  # -1.0 to +1.0
    sentiment_label = Column(String(20), nullable=False)  # positive/negative/neutral
    created_at = Column(DateTime, default=datetime.utcnow)
    
    # Relationships
    stock = relationship('Stock', back_populates='news')
    
    # Unique constraint: same URL can be used for multiple stocks
    __table_args__ = (
        Index('idx_news_url', 'stock_id', 'url', unique=True),
        Index('idx_published', 'published_at'),  # For time-based queries
    )


class Recommendation(Base):
    """ML-generated recommendations"""
    __tablename__ = 'recommendations'
    
    id = Column(Integer, primary_key=True)
    stock_id = Column(Integer, ForeignKey('stocks.id'), nullable=False)
    overall_score = Column(Integer, nullable=False)  # 0-100
    technical_score = Column(Integer)
    fundamental_score = Column(Integer)
    sentiment_score = Column(Integer)
    signals = Column(JSON)  # List of key signals
    rank = Column(Integer)  # 1-10 for top picks
    price_at_recommendation = Column(Float)
    return_5days = Column(Float)  # Track performance
    return_30days = Column(Float)
    created_at = Column(DateTime, default=datetime.utcnow)
    
    # Relationships
    stock = relationship('Stock', back_populates='recommendations')
    
    # Index for performance tracking
    __table_args__ = (
        Index('idx_rec_date', 'created_at'),
        Index('idx_rec_score', 'overall_score'),
    )
```

### Database Statistics

```sql
-- Current database stats (your system)

SELECT 'stocks' as table_name, COUNT(*) as count FROM stocks
UNION ALL
SELECT 'stock_prices', COUNT(*) FROM stock_prices
UNION ALL
SELECT 'news_articles', COUNT(*) FROM news_articles
UNION ALL
SELECT 'recommendations', COUNT(*) FROM recommendations;

-- Results:
-- stocks:        483
-- stock_prices:  ~608,000 (483 √ó 5 years √ó 252 days)
-- news_articles: ~2,000-4,000
-- recommendations: Variable (generated on-demand)

-- Database size: ~65 MB
-- Index size: ~5 MB
-- Total: ~70 MB
```

---

## API Integrations

### 1. yfinance (Historical Stock Prices)

```python
# Usage in collectors.py

import yfinance as yf

def fetch_price_history(ticker, period='5y'):
    """
    Fetch historical OHLCV data from Yahoo Finance
    
    Pros:
    - Unlimited requests (best effort)
    - Reliable data quality
    - Adjusted for splits/dividends
    - 100% free
    
    Cons:
    - Rate limiting (if too aggressive)
    - Occasional API hiccups
    - No guaranteed SLA
    
    Period options:
    - '1d', '5d', '1mo', '3mo', '6mo', '1y', '2y', '5y', '10y', 'max'
    """
    try:
        # Download data
        stock = yf.Ticker(ticker)
        df = stock.history(period=period, interval='1d')
        
        # Process
        df.reset_index(inplace=True)
        df.columns = ['date', 'open', 'high', 'low', 'close', 'volume', ...]
        
        # Handle timezone (convert to naive)
        if df['date'].dt.tz is not None:
            df['date'] = df['date'].dt.tz_localize(None)
        
        return df
        
    except Exception as e:
        logger.error(f"yfinance error for {ticker}: {e}")
        return None
```

### 2. Finnhub (Real-time Quotes & Company Info)

```python
# Usage in collectors.py

import finnhub

def fetch_company_info(ticker):
    """
    Fetch company profile from Finnhub
    
    API Limits:
    - Free tier: 60 calls/minute
    - 483 stocks = 8 minutes max
    
    Returns:
    - name: Company name
    - sector: Business sector
    - industry: Specific industry
    - market_cap: Market capitalization
    """
    try:
        client = finnhub.Client(api_key=self.finnhub_api_key)
        profile = client.company_profile2(symbol=ticker)
        
        return {
            'name': profile.get('name'),
            'sector': profile.get('finnhubIndustry'),
            'industry': profile.get('finnhubIndustry'),
            'market_cap': profile.get('marketCapitalization', 0) * 1000000  # Convert to dollars
        }
        
    except Exception as e:
        logger.error(f"Finnhub error for {ticker}: {e}")
        return None
```

### 3. NewsAPI (News Articles)

```python
# Usage in collectors.py

import requests

def fetch_news(ticker, days_back=7):
    """
    Fetch news articles from NewsAPI
    
    API Limits:
    - Free tier: 500 requests/day
    - 483 stocks = within limit (just barely!)
    
    Query structure:
    - Keywords: ticker OR company_name
    - Date range: Last 7 days
    - Language: English
    - Sort: Relevancy
    
    Returns list of articles:
    - title
    - source
    - url
    - published_at
    """
    from_date = (datetime.now() - timedelta(days=days_back)).strftime('%Y-%m-%d')
    
    params = {
        'apiKey': self.api_key,
        'q': f'({ticker} OR "{company_name}")',
        'from': from_date,
        'language': 'en',
        'sortBy': 'relevancy',
        'pageSize': 10
    }
    
    response = requests.get('https://newsapi.org/v2/everything', params=params)
    
    if response.status_code == 200:
        articles = response.json()['articles']
        return [{
            'title': a['title'],
            'source': a['source']['name'],
            'url': a['url'],
            'published_at': a['publishedAt']
        } for a in articles]
    else:
        return []
```

### 4. FinBERT (Sentiment Analysis - Local)

```python
# Usage in collectors.py

from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch

class SentimentAnalyzer:
    """
    FinBERT sentiment analysis
    
    Model: ProsusAI/finbert
    - Pre-trained on financial news
    - Fine-tuned for sentiment classification
    - Runs locally (no API needed!)
    
    Output:
    - sentiment_score: -1.0 to +1.0
    - sentiment_label: positive/negative/neutral
    - confidence_scores: probabilities for each class
    """
    
    def __init__(self):
        self.tokenizer = AutoTokenizer.from_pretrained('ProsusAI/finbert')
        self.model = AutoModelForSequenceClassification.from_pretrained('ProsusAI/finbert')
        self.model.eval()  # Evaluation mode
    
    def analyze_text(self, text):
        """
        Analyze sentiment of text
        
        Process:
        1. Tokenize text
        2. Pass through BERT model
        3. Get probabilities for pos/neg/neu
        4. Calculate score: pos - neg
        5. Return label with highest probability
        """
        # Tokenize
        inputs = self.tokenizer(
            text,
            return_tensors='pt',
            truncation=True,
            max_length=512,
            padding=True
        )
        
        # Get predictions
        with torch.no_grad():
            outputs = self.model(**inputs)
            probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)
        
        # Extract scores
        # Model outputs: [negative, neutral, positive]
        neg_score = probabilities[0][0].item()
        neu_score = probabilities[0][1].item()
        pos_score = probabilities[0][2].item()
        
        # Calculate sentiment score (-1 to +1)
        sentiment_score = pos_score - neg_score
        
        # Determine label
        max_idx = torch.argmax(probabilities[0]).item()
        labels = ['negative', 'neutral', 'positive']
        sentiment_label = labels[max_idx]
        
        return {
            'sentiment_score': sentiment_score,
            'sentiment_label': sentiment_label,
            'confidence_scores': {
                'positive': pos_score,
                'negative': neg_score,
                'neutral': neu_score
            }
        }
```

### API Usage Summary

| API | Purpose | Free Tier Limit | Current Usage | Cost |
|-----|---------|-----------------|---------------|------|
| **yfinance** | Historical prices | Unlimited (best effort) | 483 calls/load, 483/day refresh | $0 |
| **Finnhub** | Company info, real-time | 60/min, 1M/month | 483 calls/load, minimal refresh | $0 |
| **NewsAPI** | News articles | 500/day | 483/day | $0 |
| **FinBERT** | Sentiment analysis | Unlimited (local) | ~2-4K/day | $0 |
| **FMP** | Fundamentals (optional) | 250/day | Not required | $0 |
| **Total** | | | | **$0/month** |

---

## Code Structure

### Project Organization

```
smartinvest-bot/
‚îÇ
‚îú‚îÄ‚îÄ README.md                          # Project overview
‚îú‚îÄ‚îÄ requirements.txt                   # Python dependencies
‚îú‚îÄ‚îÄ config.py                          # Configuration management
‚îú‚îÄ‚îÄ .env                               # API keys (not in git)
‚îú‚îÄ‚îÄ bot_with_real_data.py             # Main Discord bot
‚îÇ
‚îú‚îÄ‚îÄ data/                              # Data layer
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ collectors.py                  # API data collection
‚îÇ   ‚îú‚îÄ‚îÄ storage.py                     # Database operations
‚îÇ   ‚îú‚îÄ‚îÄ schema.py                      # SQLAlchemy models
‚îÇ   ‚îî‚îÄ‚îÄ pipeline.py                    # Data processing pipelines
‚îÇ
‚îú‚îÄ‚îÄ features/                          # Feature engineering
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ technical.py                   # Technical indicators
‚îÇ   ‚îú‚îÄ‚îÄ fundamental.py                 # Fundamental metrics
‚îÇ   ‚îî‚îÄ‚îÄ sentiment.py                   # Sentiment aggregation
‚îÇ
‚îú‚îÄ‚îÄ models/                            # Machine learning
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ training.py                    # Model training
‚îÇ   ‚îú‚îÄ‚îÄ feature_pipeline.py            # Feature transformation
‚îÇ   ‚îú‚îÄ‚îÄ scoring.py                     # Stock scoring
‚îÇ   ‚îî‚îÄ‚îÄ saved_models/                  # Serialized models
‚îÇ       ‚îî‚îÄ‚îÄ model_latest.pkl           # Current production model
‚îÇ
‚îú‚îÄ‚îÄ utils/                             # Utilities
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ helpers.py                     # Helper functions
‚îÇ   ‚îî‚îÄ‚îÄ validators.py                  # Input validation
‚îÇ
‚îú‚îÄ‚îÄ scripts/                           # Operational scripts
‚îÇ   ‚îú‚îÄ‚îÄ load_full_sp500.py            # Initial stock load
‚îÇ   ‚îú‚îÄ‚îÄ daily_refresh.py              # Daily data refresh
‚îÇ   ‚îú‚îÄ‚îÄ fetch_news_sentiment.py       # News collection
‚îÇ   ‚îú‚îÄ‚îÄ train_model_v2.py             # ML training
‚îÇ   ‚îî‚îÄ‚îÄ setup_cron.py                 # Automation setup
‚îÇ
‚îú‚îÄ‚îÄ docs/                              # Documentation
‚îÇ   ‚îú‚îÄ‚îÄ COMPLETE_TECHNICAL_GUIDE.md   # This document
‚îÇ   ‚îú‚îÄ‚îÄ AUTOMATION_GUIDE.md           # Automation setup
‚îÇ   ‚îú‚îÄ‚îÄ EXPANSION_PLAN.md             # Future roadmap
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ
‚îú‚îÄ‚îÄ logs/                              # Log files
‚îÇ   ‚îî‚îÄ‚îÄ daily_refresh.log             # Cron job logs
‚îÇ
‚îú‚îÄ‚îÄ archive/                           # Old/backup files
‚îÇ   ‚îú‚îÄ‚îÄ old_scripts/                  # Deprecated scripts
‚îÇ   ‚îî‚îÄ‚îÄ tests/                        # Old test files
‚îÇ
‚îú‚îÄ‚îÄ smartinvest_dev.db                # SQLite database
‚îî‚îÄ‚îÄ venv/                             # Python virtual environment
```

### Key Files Explained

#### `bot_with_real_data.py` (716 lines)
Main Discord bot application. Contains:
- Bot initialization and configuration
- Command definitions (/daily, /stock, /performance, /train)
- Recommendation generation logic
- ML model integration
- Discord embed formatting
- Scheduled tasks

#### `data/collectors.py` (1,068 lines)
Data collection from external APIs:
- `StockDataCollector`: yfinance, Finnhub, FMP integration
- `NewsCollector`: NewsAPI integration
- `SentimentAnalyzer`: FinBERT sentiment analysis
- Rate limiting and error handling
- Retry logic with exponential backoff

#### `data/storage.py` (637 lines)
Database operations:
- `DatabaseManager`: High-level DB interface
- CRUD operations for stocks, prices, news, recommendations
- Bulk insert optimization
- Query methods with filtering
- Transaction management

#### `data/schema.py` (200+ lines)
SQLAlchemy ORM models:
- `Stock`: Stock master table
- `StockPrice`: Historical OHLCV data
- `NewsArticle`: News with sentiment
- `Recommendation`: ML recommendations
- `UserWatchlist`: User-specific data
- `UserAlert`: Alert configuration

#### `models/training.py` (400+ lines)
ML model training:
- `StockMLModel`: XGBoost training class
- Data preparation and feature engineering
- Train/test split and cross-validation
- Model evaluation and metrics
- Model persistence (joblib)

#### `scripts/daily_refresh.py` (305 lines)
Automated daily data refresh:
- Price updates for all stocks
- News and sentiment updates
- Fundamental updates (optional)
- Incremental updates (preserves history)
- Comprehensive logging

---

## Data Flow

### Complete Request Flow (User ‚Üí Response)

```
USER TYPES /daily IN DISCORD
    ‚îÇ
    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 1. DISCORD BOT RECEIVES COMMAND                             ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ bot_with_real_data.py:daily_command()                       ‚îÇ
‚îÇ ‚Ä¢ Parse command                                              ‚îÇ
‚îÇ ‚Ä¢ Defer response (processing...)                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
                            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 2. GENERATE RECOMMENDATIONS                                  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ bot_with_real_data.py:generate_recommendations()            ‚îÇ
‚îÇ ‚Ä¢ Load all stocks from database (483 stocks)                ‚îÇ
‚îÇ ‚Ä¢ For each stock, call score_stock_simple()                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
                            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 3. SCORE INDIVIDUAL STOCK (√ó483)                            ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ bot_with_real_data.py:score_stock_simple(ticker)            ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ A. Load data from database:                                 ‚îÇ
‚îÇ    ‚Ä¢ Price history (last 60 days)                           ‚îÇ
‚îÇ    ‚Ä¢ News articles (last 30 days)                           ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ B. Calculate technical features:                            ‚îÇ
‚îÇ    features/technical.py:                                    ‚îÇ
‚îÇ    ‚Ä¢ RSI, MACD, Bollinger Bands                             ‚îÇ
‚îÇ    ‚Ä¢ Moving averages, momentum                              ‚îÇ
‚îÇ    ‚Ä¢ Volume trends, volatility                              ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ C. Calculate sentiment features:                            ‚îÇ
‚îÇ    features/sentiment.py:                                    ‚îÇ
‚îÇ    ‚Ä¢ Weighted sentiment score                               ‚îÇ
‚îÇ    ‚Ä¢ Positive/negative counts                               ‚îÇ
‚îÇ    ‚Ä¢ Sentiment consistency                                  ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ D. ML prediction:                                           ‚îÇ
‚îÇ    models/scoring.py:                                        ‚îÇ
‚îÇ    ‚Ä¢ Load model_latest.pkl                                  ‚îÇ
‚îÇ    ‚Ä¢ Prepare feature vector                                 ‚îÇ
‚îÇ    ‚Ä¢ Get ML probability (0-1)                               ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ E. Calculate overall score:                                 ‚îÇ
‚îÇ    ‚Ä¢ Technical: 30%                                         ‚îÇ
‚îÇ    ‚Ä¢ Sentiment: 30%                                         ‚îÇ
‚îÇ    ‚Ä¢ ML prediction: 40%                                     ‚îÇ
‚îÇ    ‚Ä¢ Result: 0-100 score                                    ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ F. Generate signals:                                        ‚îÇ
‚îÇ    ‚Ä¢ "RSI oversold" if RSI < 30                            ‚îÇ
‚îÇ    ‚Ä¢ "MACD bullish crossover" if MACD > Signal             ‚îÇ
‚îÇ    ‚Ä¢ "Positive sentiment" if sentiment > 0.5               ‚îÇ
‚îÇ    ‚Ä¢ "ML confidence: 87%" if ML prob = 0.87                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
                            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 4. RANK & SELECT TOP 10                                      ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ ‚Ä¢ Sort all 483 stocks by overall_score (descending)         ‚îÇ
‚îÇ ‚Ä¢ Take top 10 highest-scoring stocks                        ‚îÇ
‚îÇ ‚Ä¢ Example:                                                   ‚îÇ
‚îÇ   1. NVDA (score: 92)                                       ‚îÇ
‚îÇ   2. AAPL (score: 87)                                       ‚îÇ
‚îÇ   3. MSFT (score: 84)                                       ‚îÇ
‚îÇ   ...                                                        ‚îÇ
‚îÇ   10. AMD (score: 72)                                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
                            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 5. FORMAT DISCORD EMBED                                      ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ bot_with_real_data.py:create_recommendations_embed()        ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ ‚Ä¢ Create rich embed with:                                   ‚îÇ
‚îÇ   - Title: "Top 10 Daily Recommendations"                   ‚îÇ
‚îÇ   - Color: Green (success)                                  ‚îÇ
‚îÇ   - Timestamp                                               ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ ‚Ä¢ For each stock:                                           ‚îÇ
‚îÇ   - Emoji (üü¢/üü°/‚ö™/üî¥) based on score                      ‚îÇ
‚îÇ   - Ticker + company name                                   ‚îÇ
‚îÇ   - Overall score + rating (BUY/SELL)                       ‚îÇ
‚îÇ   - Current price                                           ‚îÇ
‚îÇ   - Top 3 key signals                                       ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ ‚Ä¢ Footer: "SmartInvest Bot ‚Ä¢ ML-Powered"                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
                            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 6. SEND TO USER                                              ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ await interaction.followup.send(embed=embed)                 ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ User sees beautiful formatted message in Discord with        ‚îÇ
‚îÇ top 10 stock recommendations!                                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

TOTAL TIME: ~5-10 seconds for 483 stocks
```

### Daily Refresh Flow

```
6:00 AM - CRON JOB TRIGGERS
    ‚îÇ
    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ scripts/daily_refresh.py                                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
                            ‚îú‚îÄ‚ñ∫ STEP 1: UPDATE PRICES
                            ‚îÇ   ‚îÇ
                            ‚îÇ   ‚îú‚îÄ Get all 483 stocks
                            ‚îÇ   ‚îÇ
                            ‚îÇ   ‚îú‚îÄ For each stock:
                            ‚îÇ   ‚îÇ  ‚Ä¢ Check latest date in DB
                            ‚îÇ   ‚îÇ  ‚Ä¢ Fetch new data from yfinance
                            ‚îÇ   ‚îÇ  ‚Ä¢ Filter to new records only
                            ‚îÇ   ‚îÇ  ‚Ä¢ Bulk insert (preserves history)
                            ‚îÇ   ‚îÇ
                            ‚îÇ   ‚îî‚îÄ Result: +483 new price records
                            ‚îÇ       Time: ~5 minutes
                            ‚îÇ
                            ‚îú‚îÄ‚ñ∫ STEP 2: UPDATE FUNDAMENTALS (optional)
                            ‚îÇ   ‚îÇ
                            ‚îÇ   ‚îî‚îÄ Skipped (FMP API not available)
                            ‚îÇ       Time: 0 minutes
                            ‚îÇ
                            ‚îî‚îÄ‚ñ∫ STEP 3: UPDATE NEWS & SENTIMENT
                                ‚îÇ
                                ‚îú‚îÄ For each stock:
                                ‚îÇ  ‚Ä¢ Fetch last 7 days news (NewsAPI)
                                ‚îÇ  ‚Ä¢ Analyze sentiment (FinBERT)
                                ‚îÇ  ‚Ä¢ Save new articles (duplicates handled)
                                ‚îÇ
                                ‚îî‚îÄ Result: +100-500 new articles
                                    Time: ~8 minutes
                                    
6:15 AM - COMPLETE, LOGGED
    ‚îÇ
    ‚îî‚îÄ‚ñ∫ logs/daily_refresh.log updated
        Database now has latest data!
```

---

## Deployment

### Environment Setup

```bash
# 1. Clone repository
git clone <your-repo-url>
cd smartinvest-bot

# 2. Create virtual environment
python3.11 -m venv venv
source venv/bin/activate  # macOS/Linux
# OR
venv\Scripts\activate     # Windows

# 3. Install dependencies
pip install -r requirements.txt

# 4. Create .env file
cat > .env << EOF
DISCORD_BOT_TOKEN=your_discord_token
DISCORD_CHANNEL_ID=your_channel_id
NEWS_API_KEY=your_newsapi_key
FINNHUB_API_KEY=your_finnhub_key
FMP_API_KEY=your_fmp_key
DATABASE_URL=sqlite:///smartinvest_dev.db
ENVIRONMENT=production
EOF

# 5. Initialize database
python -c "
from config import Config
from data.storage import DatabaseManager
db = DatabaseManager(Config.DATABASE_URL)
db.create_all_tables()
print('Database initialized!')
"

# 6. Load stocks
python scripts/load_full_sp500.py

# 7. Fetch news & sentiment
python scripts/fetch_news_sentiment.py

# 8. Train ML model
python scripts/train_model_v2.py

# 9. Setup automation
python scripts/setup_cron.py

# 10. Start bot
python bot_with_real_data.py
```

### Production Considerations

#### 1. Process Management

```bash
# Use systemd (Linux) for production

# /etc/systemd/system/smartinvest-bot.service
[Unit]
Description=SmartInvest Discord Bot
After=network.target

[Service]
Type=simple
User=your_user
WorkingDirectory=/path/to/smartinvest-bot
ExecStart=/path/to/venv/bin/python bot_with_real_data.py
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target

# Enable and start
sudo systemctl enable smartinvest-bot
sudo systemctl start smartinvest-bot
```

#### 2. Monitoring

```bash
# Check bot status
systemctl status smartinvest-bot

# View logs
journalctl -u smartinvest-bot -f

# Check daily refresh logs
tail -f logs/daily_refresh.log

# Database size monitoring
watch -n 60 'ls -lh smartinvest_dev.db'
```

#### 3. Backup Strategy

```bash
# Daily database backup
# Add to crontab:
0 2 * * * cp /path/to/smartinvest_dev.db /path/to/backups/smartinvest_$(date +\%Y\%m\%d).db

# Weekly cleanup (keep last 30 days)
0 3 * * 0 find /path/to/backups/ -name "smartinvest_*.db" -mtime +30 -delete
```

---

## Performance & Scaling

### Current Performance

```
METRICS (483 stocks)
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

Database Operations:
  ‚Ä¢ Query all stocks: ~50ms
  ‚Ä¢ Get price history (60 days): ~10ms
  ‚Ä¢ Get news articles (30 days): ~5ms
  ‚Ä¢ Bulk insert prices: ~100ms (500 records)

ML Scoring:
  ‚Ä¢ Score single stock: ~20ms
  ‚Ä¢ Score all 483 stocks: ~10 seconds
  ‚Ä¢ Model load time: ~200ms (first time)
  ‚Ä¢ Model inference: <1ms per stock

Discord Commands:
  ‚Ä¢ /daily (top 10): ~12 seconds
  ‚Ä¢ /stock <ticker>: ~2 seconds
  ‚Ä¢ /performance: ~1 second

Daily Refresh:
  ‚Ä¢ Update prices (483): ~5 minutes
  ‚Ä¢ Update news (483): ~8 minutes
  ‚Ä¢ Total: ~13 minutes
  ‚Ä¢ Database writes: ~1,000/refresh

Memory Usage:
  ‚Ä¢ Bot idle: ~200 MB
  ‚Ä¢ Bot active (scoring): ~400 MB
  ‚Ä¢ Daily refresh: ~300 MB
  ‚Ä¢ ML training: ~1 GB
```

### Scaling Considerations

#### Scale to 1,000 Stocks

```
CHANGES NEEDED:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

1. Database:
   ‚Ä¢ SQLite ‚Üí PostgreSQL (better concurrent writes)
   ‚Ä¢ Add connection pooling
   ‚Ä¢ Optimize indices

2. API Limits:
   ‚Ä¢ NewsAPI: 500/day ‚Üí 1,000/day (need paid tier $449/mo)
   ‚Ä¢ Or: Switch to alternative news API
   ‚Ä¢ yfinance: Still free (no change)
   ‚Ä¢ Finnhub: Still within limits

3. ML Training:
   ‚Ä¢ 1,000 stocks √ó 90 days = 90K training samples
   ‚Ä¢ Training time: ~5-10 minutes (still acceptable)
   ‚Ä¢ Consider GPU acceleration for faster training

4. Daily Refresh:
   ‚Ä¢ ~30 minutes (2√ó current)
   ‚Ä¢ Consider parallel processing (multiprocessing)
   ‚Ä¢ Or: Split into 2 runs (500 each)

5. Discord Bot:
   ‚Ä¢ Score 1,000 stocks: ~20 seconds
   ‚Ä¢ Add caching for recent scores
   ‚Ä¢ Implement background scoring

ESTIMATED COSTS:
  ‚Ä¢ NewsAPI paid tier: $449/month
  ‚Ä¢ Server (AWS t3.medium): $30/month
  ‚Ä¢ PostgreSQL (RDS): $15/month
  ‚Ä¢ Total: ~$500/month
```

#### Optimization Strategies

**1. Database Optimization**
```python
# Add indices for common queries
CREATE INDEX idx_stock_ticker ON stocks(ticker);
CREATE INDEX idx_price_date ON stock_prices(date);
CREATE INDEX idx_news_published ON news_articles(published_at);

# Use query optimization
db_manager.get_price_history_optimized(stock_id, days=60)
# Instead of loading all data, use SQL LIMIT

# Implement connection pooling
engine = create_engine(
    DATABASE_URL,
    pool_size=10,
    max_overflow=20
)
```

**2. ML Inference Caching**
```python
# Cache scores for N minutes
from functools import lru_cache
from datetime import datetime

@lru_cache(maxsize=500)
def score_stock_cached(ticker, cache_time):
    """Cache scores for 15 minutes"""
    return score_stock_simple(ticker)

# Call with rounded timestamp
cache_key = datetime.now().replace(minute=datetime.now().minute // 15 * 15)
result = score_stock_cached(ticker, cache_key)
```

**3. Parallel Processing**
```python
# Score multiple stocks in parallel
from concurrent.futures import ThreadPoolExecutor

def score_all_stocks_parallel(tickers):
    with ThreadPoolExecutor(max_workers=10) as executor:
        results = list(executor.map(score_stock_simple, tickers))
    return results

# 10√ó faster for bulk scoring!
```

**4. Async Discord Bot**
```python
# Use async/await for non-blocking operations
async def generate_recommendations_async(top_n=10):
    loop = asyncio.get_event_loop()
    
    # Run blocking ML scoring in thread pool
    with ThreadPoolExecutor() as pool:
        recommendations = await loop.run_in_executor(
            pool, 
            generate_recommendations,
            top_n
        )
    
    return recommendations
```

---

## Appendix

### Key Dependencies

```
requirements.txt
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

# Discord
discord.py==2.3.2

# Data Collection
yfinance==0.2.28
finnhub-python==2.4.18
requests==2.31.0

# Machine Learning
xgboost==2.0.0
scikit-learn==1.3.0
transformers==4.33.0
torch==2.0.1

# Data Processing
pandas==2.0.3
numpy==1.24.3

# Database
SQLAlchemy==2.0.20
python-dotenv==1.0.0

# Utilities
joblib==1.3.2
python-dateutil==2.8.2
```

### Useful Commands

```bash
# Development
python bot_with_real_data.py              # Run bot
python scripts/load_full_sp500.py         # Load stocks
python scripts/fetch_news_sentiment.py    # Load news
python scripts/train_model_v2.py          # Train model
python scripts/daily_refresh.py           # Test refresh

# Database
sqlite3 smartinvest_dev.db                # Open DB
.schema stocks                            # View schema
SELECT COUNT(*) FROM stocks;              # Count stocks
SELECT COUNT(*) FROM stock_prices;        # Count prices

# Monitoring
tail -f logs/daily_refresh.log            # View logs
ps aux | grep python                      # Check processes
du -sh smartinvest_dev.db                 # DB size

# Automation
crontab -l                                # View cron jobs
crontab -e                                # Edit cron jobs
systemctl status smartinvest-bot          # Check service
```

### Common Issues & Solutions

**Issue: Bot not responding in Discord**
```bash
# Check if bot is running
ps aux | grep bot_with_real_data

# Check logs
tail -50 logs/daily_refresh.log

# Restart bot
pkill -f bot_with_real_data
python bot_with_real_data.py &
```

**Issue: Database locked**
```bash
# Kill any processes using the DB
lsof smartinvest_dev.db
kill <PID>

# Or restart entirely
pkill -f python
python bot_with_real_data.py &
```

**Issue: ML model not found**
```bash
# Retrain model
python scripts/train_model_v2.py

# Check if file exists
ls -lh models/saved_models/model_latest.pkl
```

---

## Conclusion

SmartInvest is a production-grade, automated stock analysis system that combines:
- **Real-time data** from multiple free APIs
- **Machine learning** with 84% accuracy
- **Sentiment analysis** using state-of-the-art FinBERT
- **Discord interface** for easy access
- **Full automation** with zero maintenance

The system is designed to scale, maintain historical data forever, and provide reliable stock recommendations through a user-friendly Discord interface.

**Total Cost:** $0/month  
**Maintenance:** <5 minutes/week  
**Uptime:** 24/7  
**Data Coverage:** 483 S&P 500 stocks  
**ML Accuracy:** 84%  

---

**Document Version:** 1.0  
**Last Updated:** November 11, 2025  
**Author:** SmartInvest Team

